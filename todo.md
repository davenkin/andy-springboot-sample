- Mongo
    - 不用spring的repository
    - 启用transaction
    - 使用mongock，命名规范
- ShedLock
    - 直接用于定时任务
    - LockingTaskExecutor可以直接调用
- CommandService
    - 需要将Principal传进去，从CommandService以后就不要再依赖ThreadLocal来获取Spring Security中的用户信息了
    - 门面，标定一次用例，不应该只为HTTP的controller服务
- HTTP请求处理流程
    - 写数据请求，command service是门面，是业务用例的入口，然后通过repository加载聚合根对象，调用聚合根对象上的业务方法，再通过repository保存聚合根
    - 读数据请求
    - command，query，response使用record表示
- 异常处理
- 缓存
- 为基础设施添加测试
- 优先使用record
- 由于测试运行时没有启动redis，因此在引入新的缓存对象时，请在本地运行保证缓存能够正常地工作，比如缓存是否生效以及序列化/反序列化是否正常工作，通过在BaseTest中启用local
  profile可以完成测试
- ar的id需要全局唯一，不能在org下唯一，可以直接通过id定位到一个ar，而不用必须传入orgId，当然在业务上需要orgId来界定时，比如同时传入id和orgId
- 接收请求时，我们需要保证org是可信的，即：
    - 如果是root用户，可以通过http的header传入orgId
    - 如果是org下的用户，那么必须从JWT中获取orgId
- WebClient：1，使用当前用户的jwt，2，使用service account
- never use @Data
- 时间戳全部用Instant
- EventConsumer只所以使用自己的retry而不直接使用spring kafka的，主要是是我们当前的事件消费机制是一个事件可以被多个event
  handler独立消费，因此需要为每个event handler独立进行retry，而spring kafka无法做到这一点。
- event和event handler不能随便移动位置，因为：
    - event：spring kafka通过event的FQCN进行序列化和反序列化
    - event handler：事件处理机制通过event handler的 FQCN来达到幂等消费，具体请参考`ConsumingEventDao.recordAsConsumed()`
- 全局尽量使用同一个ObjectMapper实例
- 我们不使用spring security进行角色验证，而是在command service中通过Principal.checkHasRole()
  等方法验证权限，让权限管控离业务逻辑更近，更具内聚性，另外也方便以后扩展成ARBC。
- 如何使用pagination和sorting，可以使用spring的Pageable和Page<>
- 算了，不要typealias了，
- 测试mongock是否有效
- 不使用spring data repository
- 集成测试尽量不用mock
- 测试方法采用下划线格式
- 任何ID都由程序自己生成，而不用数据库生成，比如Equipment.newEquipmentId();
- 当需要引用对象字段时，使用@FieldNameConstants
- ID不由数据库生成，有代码自己生成
- AggregateRoot -》AbstractAggregateRoot，文档中也要改
- DomainEvent -》 AbstractDomainEvent，文档中也要改
